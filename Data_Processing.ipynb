{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e01c0650-537f-414c-a28a-421c0f56508d",
   "metadata": {},
   "source": [
    "# Data Processing Code\n",
    "## All the code used within the thesis for data processing work.\n",
    "## Data visualization code is contained within a separate notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4bc0f7-a70d-49e9-940f-ec12bf9d5645",
   "metadata": {},
   "source": [
    "# Taxonomic Check\n",
    "### Code reads in an Excel file of species names and checks their validity using the GBIF API.\n",
    "### ChatGPT was used to create the GBIF API function.\n",
    "### Utilized in section 3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cc7568-b487-4af9-9a95-b50f2545a473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def get_taxonomic_info(taxa):\n",
    "    base_url = \"https://api.gbif.org/v1/species/match\"\n",
    "    params = {\"name\": taxa}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"kingdom\" in data:\n",
    "            return {\n",
    "                \"Kingdom\": data.get(\"kingdom\"),\n",
    "                \"Phylum\": data.get(\"phylum\"),\n",
    "                \"Class\": data.get(\"class\"),\n",
    "                \"Order\": data.get(\"order\"),\n",
    "                \"Family\": data.get(\"family\"),\n",
    "                \"Genus\": data.get(\"genus\"),\n",
    "                \"Species\": data.get(\"species\"),\n",
    "                \"Scientific Name\": data.get(\"scientificName\"),\n",
    "                \"Rank\": data.get(\"rank\"),\n",
    "                \"Status\": data.get(\"status\"),\n",
    "                \"Confidence\": data.get(\"confidence\"),\n",
    "                \"Canonical Name\": data.get(\"canonicalName\"),\n",
    "            }\n",
    "        else:\n",
    "            return {\"Error\": \"Taxa not found.\"}\n",
    "    else:\n",
    "        return {\"Error\": f\"Failed to fetch data (Status Code: {response.status_code})\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46962493-aaaa-4cf3-825f-5359389a3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_excel(\"Data/species.xlsx\")\n",
    "\n",
    "# Empty results list\n",
    "taxonomic_results = []\n",
    "\n",
    "# Retrieve taxonomic information for each taxa in the excel file\n",
    "for taxa in df[\"Taxa\"]:\n",
    "    taxonomic_results.append(get_taxonomic_info(taxa))\n",
    "\n",
    "# Convert results to dataframe\n",
    "results = pd.DataFrame(taxonomic_results)\n",
    "\n",
    "# Convert dataframe to excel\n",
    "results.to_excel(\"Output/taxonomic_check.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c95ea5-18e6-42fd-abb7-a93d9e868372",
   "metadata": {},
   "source": [
    "# Trade Route Creation\n",
    "## Code reads in an excel file, and parces the three different kinds of trade routes encountered (international, domestic, and incomplete). A count by country (or country combination) for complete (international and domestic) and incomplete routes is then created and exported.\n",
    "### The output data from this is used in the top species trade route maps.\n",
    "### Utlized in section 3.3.4, for section 4.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a9f34b-5916-4199-a40b-03504dcd2903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in data\n",
    "df = pd.read_excel(\"Data/routes.xlsx\")\n",
    "\n",
    "# Remove whitespace (taken from \"https://stackoverflow.com/questions/33788913/pythonic-efficient-way-to-strip-whitespace-from-every-pandas-data-frame-cell-tha\")\n",
    "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# Create empty sets and lists\n",
    "unique_routes = set()\n",
    "complete_routes = []\n",
    "incomplete_routes = []\n",
    "\n",
    "# Iterate through dataframe\n",
    "for x, row in df.iterrows():\n",
    "    label = row[\"label\"] \n",
    "    species = row[\"species\"]\n",
    "\n",
    "    # Check if domestic\n",
    "    domestic = row[\"route_type\"] == \"Domestic\"\n",
    "    \n",
    "    # Extract supply and demand columns\n",
    "    supply = row[\"supply country\"] if pd.notna(row[\"supply country\"]) else None\n",
    "    demand = row[\"demand country\"] if pd.notna(row[\"demand country\"]) else None\n",
    "    \n",
    "    # Account for up to 3 transit columns\n",
    "    transit_columns = [f\"transit country {i}\" for i in range(1, 4)]\n",
    "    transit = [row[col] for col in transit_columns if col in df.columns and pd.notna(row[col])]\n",
    "    \n",
    "    # Domestic route (source data is formatted to contain a supply country in these cases)\n",
    "    if domestic and supply:\n",
    "        route = (label, species, supply, supply)\n",
    "        if route not in unique_routes:\n",
    "            complete_routes.append((species, supply, supply, 1))\n",
    "            unique_routes.add(route)\n",
    "            \n",
    "    # Non-domestic routes\n",
    "    else:\n",
    "        # Process routes pairs in order\n",
    "        full_route = ([supply] if supply else []) + transit + ([demand] if demand else [])\n",
    "        \n",
    "        # Add complete routes (Supply, Transit and Demand)\n",
    "        for i in range(len(full_route) - 1):\n",
    "            route = (label, species, full_route[i], full_route[i + 1])\n",
    "            if route not in unique_routes:\n",
    "                complete_routes.append((species, full_route[i], full_route[i + 1], 1))\n",
    "                unique_routes.add(route)\n",
    "        \n",
    "        # Transit and Demand\n",
    "        if not supply and transit:\n",
    "            for i in range(len(transit) - 1):\n",
    "                route = (label, species, transit[i], transit[i + 1])\n",
    "                if route not in unique_routes:\n",
    "                    complete_routes.append((species, transit[i], transit[i + 1], 1))\n",
    "                    unique_routes.add(route)\n",
    "            route = (label, species, transit[-1], demand if demand else None)\n",
    "            if route not in unique_routes:\n",
    "                if demand:\n",
    "                    complete_routes.append((species, transit[-1], demand, 1))\n",
    "                else:\n",
    "                    incomplete_routes.append((species, transit[-1], None, label))\n",
    "                unique_routes.add(route)\n",
    "                \n",
    "        # Only Supply\n",
    "        if supply and not demand and not transit:\n",
    "            route = (label, species, supply, None)\n",
    "            if route not in unique_routes:\n",
    "                incomplete_routes.append((species, supply, None, label))\n",
    "                unique_routes.add(route)\n",
    "        \n",
    "        # Only Transit\n",
    "        if transit and not supply and not demand:\n",
    "            for i in range(len(transit) - 1):\n",
    "                route = (label, species, transit[i], transit[i + 1])\n",
    "                if route not in unique_routes:\n",
    "                    complete_routes.append((species, transit[i], transit[i + 1], 1))\n",
    "                    unique_routes.add(route)\n",
    "            route = (label, species, transit[-1], None)\n",
    "            if route not in unique_routes:\n",
    "                incomplete_routes.append((species, transit[-1], None, label))\n",
    "                unique_routes.add(route)\n",
    "                \n",
    "        # Only Demand\n",
    "        if demand and not supply and not transit:\n",
    "            route = (label, species, None, demand)\n",
    "            if route not in unique_routes:\n",
    "                incomplete_routes.append((species, None, demand, label))\n",
    "                unique_routes.add(route)\n",
    "                \n",
    "# Export dataframes\n",
    "complete_routes = pd.DataFrame(complete_routes, columns=[\"species\", \"origin\", \"destination\", \"count\"])\n",
    "complete_routes = complete_routes.groupby([\"species\", \"origin\", \"destination\"]).sum().reset_index()\n",
    "complete_routes.to_excel(\"Output/Complete_Routes.xlsx\", index=False)\n",
    "\n",
    "incomplete_routes = pd.DataFrame(incomplete_routes, columns=[\"species\", \"origin\", \"destination\", \"label\"])\n",
    "incomplete_routes.to_excel(\"Output/Incomplete_Routes.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
